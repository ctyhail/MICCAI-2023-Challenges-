{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "totensor = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),#垂直翻转\n",
    "        A.VerticalFlip(p=0.5),#水平翻转\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomGamma(p=1),#随机伽马变换\n",
    "                A.RandomBrightnessContrast(p=1),#随机亮度\n",
    "                A.Blur(p=1),#模糊\n",
    "                A.OpticalDistortion(p=1),#光学畸变\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.ElasticTransform(p=1),#弹性变换\n",
    "                A.GridDistortion(p=1),#网格失真\n",
    "                A.MotionBlur(p=1),#运动模糊\n",
    "                A.HueSaturationValue(p=1),#色调，饱和度值随机变化\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.mode = \"train\" if \"mask\" in os.listdir(path) else \"test\"  # 表示训练模式\n",
    "        self.path = path  # 图片路径\n",
    "        dirlist = os.listdir(path + \"image/\")  # 图片的名称\n",
    "        self.name = [n for n in dirlist if n[-3:] == \"png\"]  # 只读取图片\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name)\n",
    "\n",
    "    def __getitem__(self, index):  # 获取数据的处理方式\n",
    "        name = self.name[index]\n",
    "        # 读取原始图片和标签\n",
    "        if self.mode == \"train\":  # 训练模式\n",
    "            ori_img = cv2.imread(self.path + \"image/\" + name)  # 原始图片\n",
    "            lb_img = cv2.imread(self.path + \"mask/\" + name)  # 标签图片\n",
    "            ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)  # 转为RGB三通道图\n",
    "            lb_img = cv2.cvtColor(lb_img, cv2.COLOR_BGR2GRAY)  # 掩膜转为灰度图\n",
    "            transformed = transform(image=ori_img, mask=lb_img)\n",
    "            return totensor(transformed[\"image\"]), totensor(transformed[\"mask\"])\n",
    "\n",
    "        if self.mode == \"test\":  # 测试模式\n",
    "            ori_img = cv2.imread(self.path + \"image/\" + name)  # 原始图片\n",
    "            ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)  # 转为RGB三通道图\n",
    "            return totensor(ori_img)\n",
    "\n",
    "\n",
    "def get_data(\n",
    "    mode,\n",
    "    train_path=\"train/\",\n",
    "    test_path=\"test/\",\n",
    "):\n",
    "    if mode == \"train\":\n",
    "        return MyDataset(train_path)\n",
    "    if mode == \"test\":\n",
    "        return MyDataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# dice_loss\n",
    "def dice_loss(prob, target):\n",
    "    smooth = 1.0\n",
    "    # prob = torch.sigmoid(logits)\n",
    "    batch = prob.size(0)\n",
    "    prob = prob.view(batch, 1, -1)\n",
    "    target = target.view(batch, 1, -1)\n",
    "    intersection = torch.sum(prob * target, dim=2)\n",
    "    denominator = torch.sum(prob, dim=2) + torch.sum(target, dim=2)\n",
    "    dice = (2 * intersection + smooth) / (denominator + smooth)\n",
    "    dice = torch.mean(dice)\n",
    "    dice_loss = 1.0 - dice\n",
    "    return dice_loss\n",
    "\n",
    "\n",
    "# bce_loss\n",
    "def bce_loss():\n",
    "    return torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "# bce_dice_loss\n",
    "def bce_dice_loss(prob, target):\n",
    "    bce = torch.nn.BCELoss()\n",
    "    dice = dice_loss\n",
    "    alpha = 0.2\n",
    "    return alpha * bce(prob, target) + (1 - alpha) * dice(prob, target)\n",
    "\n",
    "\n",
    "def get_loss(type):\n",
    "    if type == \"dice\":\n",
    "        return dice_loss\n",
    "    elif type == \"bce\":\n",
    "        return torch.nn.BCELoss()\n",
    "    elif type == \"bce_dice\":\n",
    "        return bce_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    name,\n",
    "    encoder_name=\"resnet50\",  # efficientnet-b5,se_resnext50_32x4d\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation=\"sigmoid\",\n",
    "):\n",
    "    if name == \"deeplabv3p\":\n",
    "        return smp.DeepLabV3Plus(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=classes,\n",
    "            activation=activation,\n",
    "        )\n",
    "    elif name == \"unetpp\":\n",
    "        return smp.UnetPlusPlus(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=classes,\n",
    "            activation=activation,\n",
    "        )\n",
    "    elif name == \"unet\":\n",
    "        return smp.Unet(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=classes,\n",
    "            activation=activation,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\"\"\"\n",
    "from model import get_model\n",
    "from data import get_data\n",
    "from loss import get_loss\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def val(val_loader, model, device, loss_fun):\n",
    "    model.eval()\n",
    "    val_loss_total = 0\n",
    "    for step, (inputs, labels) in enumerate(val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(inputs)\n",
    "        loss = loss_fun(out, labels)\n",
    "        val_loss_total += loss.item()\n",
    "    loss_val = val_loss_total / len(val_loader)\n",
    "    return loss_val\n",
    "\n",
    "\n",
    "def train(\n",
    "    model_name,\n",
    "    traindataset,\n",
    "    valdataset,\n",
    "    checkpoint_path,\n",
    "    model_save_path,\n",
    "    loss_name,\n",
    "    epochs,\n",
    "    lr=4e-3,\n",
    "    weight_decay=0,\n",
    "    step_size=20,\n",
    "    gamma=0.5,\n",
    "    batch_size=16,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = get_model(model_name).to(device)\n",
    "    if checkpoint_path:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "    model.train()\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=step_size, gamma=gamma)\n",
    "    trainloader = DataLoader(traindataset, batch_size=batch_size, shuffle=True)\n",
    "    valdataset = DataLoader(valdataset, batch_size=batch_size, shuffle=True)\n",
    "    loss_f = get_loss(loss_name)\n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "    loss_last = [99999, 99999]\n",
    "    best_model_name = \"\"\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss_total = 0\n",
    "        for step, (inputs, labels) in tqdm(enumerate(trainloader),desc=f\"Epoch {epoch}/{epochs}\",\n",
    "                                       ascii=True, total=len(trainloader)):\n",
    "            # 原始图片和标签\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            out = model(inputs)\n",
    "            loss = loss_f(out, labels)\n",
    "            train_loss_total += loss.item()\n",
    "            # 梯度清零\n",
    "            optim.zero_grad()\n",
    "            # 梯度反向传播\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        scheduler.step()\n",
    "        loss_train = train_loss_total / len(trainloader)\n",
    "        loss_val = val(valdataset, model, device, loss_f)\n",
    "        # 损失小于上一轮则添加\n",
    "        if loss_val < loss_last[0]:\n",
    "            loss_last[0], loss_last[1] = loss_val, loss_train\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                model_save_path\n",
    "                + \"epoch{}_valloss{:.5f}_trainloss{:.5f}.pth\".format(\n",
    "                    epoch, loss_val, loss_train\n",
    "                ),\n",
    "            )\n",
    "            best_model_name = (\n",
    "                model_save_path\n",
    "                + \"epoch{}_valloss{:.5f}_trainloss{:.5f}.pth\".format(\n",
    "                    epoch, loss_val, loss_train\n",
    "                )\n",
    "            )\n",
    "        print(\n",
    "            f\"Epoch: {epoch}/{epochs},train_Loss:{loss_train:.5f},val_loss:{loss_val:.5f},dice_loss:{loss}\"\n",
    "        )\n",
    "    print(f\"best model is:{best_model_name}\")\n",
    "\n",
    "\n",
    "def k_fold_train(\n",
    "    fold_num,\n",
    "    model_name,\n",
    "    checkpoint_path,\n",
    "    model_save_path,\n",
    "    loss_name,\n",
    "    epochs=100,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0,\n",
    "    step_size=20,\n",
    "    gamma=0.5,\n",
    "    batch_size=16,\n",
    "):\n",
    "    skf = KFold(n_splits=fold_num, shuffle=True)\n",
    "    dataset = get_data(\"train\")\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(dataset)):\n",
    "        train_dataset = Subset(dataset, train_idx)\n",
    "        valid_dataset = Subset(dataset, valid_idx)\n",
    "        if not os.path.exists(model_save_path):\n",
    "            os.makedirs(model_save_path)\n",
    "        temp_save_path = model_save_path + f\"fold{fold_idx}/\"\n",
    "        if not os.path.exists(temp_save_path):\n",
    "            os.makedirs(temp_save_path)\n",
    "        print(f\"training fold {fold_idx}......\")\n",
    "        print(f\"checkpoint is saving to {temp_save_path}\")\n",
    "        train(\n",
    "            model_name=model_name,\n",
    "            traindataset=train_dataset,\n",
    "            valdataset=valid_dataset,\n",
    "            checkpoint_path=checkpoint_path,\n",
    "            model_save_path=temp_save_path,\n",
    "            loss_name=loss_name,\n",
    "            epochs=epochs,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            step_size=step_size,\n",
    "            gamma=gamma,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "\n",
    "k_fold_train(\n",
    "    fold_num=5,\n",
    "    checkpoint_path=None,\n",
    "    model_name=\"deeplabv3p\",\n",
    "    model_save_path=\"5_fold_deeplabv3p_with_se_resnext_bcedice/\",\n",
    "    loss_name=\"bce_dice\",\n",
    "    epochs=100,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    step_size=20,\n",
    "    gamma=0.5,\n",
    "    batch_size=8,\n",
    ")#optim为AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\"\"\"\n",
    "from model import get_model\n",
    "from data import get_data\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_save_path=\"infers/\"\n",
    "\n",
    "if not os.path.exists(img_save_path):\n",
    "        os.makedirs(img_save_path)\n",
    "\n",
    "def zip_files(file_paths, output_path):\n",
    "    with zipfile.ZipFile(output_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file in file_paths:\n",
    "            zipf.write(file)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer(cp_path, model_name,  threshold):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    folds = os.listdir(cp_path)\n",
    "    models = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        model_checkpoints = os.listdir(os.path.join(cp_path, fold))\n",
    "        for model_checkpoint in model_checkpoints:\n",
    "            model = get_model(model_name).to(device)\n",
    "            # print(os.path.join(path, fold, model_checkpoint))\n",
    "            weight = torch.load(\n",
    "                os.path.join(cp_path, fold, model_checkpoint), map_location=device\n",
    "            )\n",
    "            model.load_state_dict(weight)\n",
    "            model.eval()\n",
    "            models.append(model)\n",
    "    testdata = get_data(\"test\")\n",
    "    for i, inputs in tqdm(enumerate(testdata)):\n",
    "        inputs0 = inputs.reshape(1, 3, 320, 640).to(device)\n",
    "        inputs1 = inputs0.flip(dims=[2]).to(device)\n",
    "        inputs2 = inputs0.flip(dims=[3]).to(device)\n",
    "        inputs3 = inputs0.flip(dims=[2, 3]).to(device)\n",
    "        out = 0\n",
    "        for model in models:\n",
    "            out0 = model(inputs0)\n",
    "            out1 = model(inputs1).flip(dims=[2])\n",
    "            out2 = model(inputs2).flip(dims=[3])\n",
    "            out3 = model(inputs3).flip(dims=[2, 3])\n",
    "            out = out + out0 + out1 + out2 + out3\n",
    "        out = out / len(models)\n",
    "        threshold = threshold\n",
    "        out = torch.where(\n",
    "            out >= threshold, torch.tensor(255, dtype=torch.float).to(device), out\n",
    "        )\n",
    "        out = torch.where(\n",
    "            out < threshold, torch.tensor(0, dtype=torch.float).to(device), out\n",
    "        )\n",
    "        out = out.detach().cpu().numpy().reshape(1, 320, 640)\n",
    "        img = Image.fromarray(out[0].astype(np.uint8))\n",
    "        img = img.convert(\"1\")\n",
    "        img.save(img_save_path + testdata.name[i])\n",
    "\n",
    "        \n",
    "\n",
    "infer(\n",
    "    model_name=\"deeplabv3p\",\n",
    "    cp_path=\"cp_v2\",\n",
    "    threshold=0.5,\n",
    ")\n",
    "\n",
    "file_paths = [img_save_path + i for i in os.listdir(img_save_path) if i[-3:] == \"png\"]\n",
    "zip_out_path = \"infer.zip\"\n",
    "zip_files(file_paths, zip_out_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
